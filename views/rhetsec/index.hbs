<div class="row justify-content-center mb-5">
  <h1 align="center">&Lt; rhetoric + cybersecurity = &#10084; &Gt;</h1>
</div>

<div class="d-lg-block d-none">
  <div class="row justify-content-center mb-5">
      <h5 align="center">
        <a href="#">_the project_</a>
        ░ <a href="./rationale">rationale</a>
        ░ <a href="./limitations">limitations</a>
        ░ <a href="./assessment">self-assessment</a>
    </h5>
  </div>
</div>

<div class="d-lg-none">
  <div class="row justify-content-center mb-5">
    <h5 align="center">
       <a href="#">_the project_</a> &#8286;
       <a href="./rationale">rationale</a> &#8286;
       <a href="./limitations">limitations</a> &#8286;
       <a href="./assessment">self-assessment</a>
    </h5>
  </div>
</div>


  <p>Now that you're here, I'm assuming you'd like to know why I've got all this security and secrecy. Rest assured, there is a reason: there is a change in how security professionals (and corporations) are managing risk when it comes to end-users. Companies are catching on that their existing platforms aren't working as well as they should be, and that it's primarily due to human factors. No doubt this is due to the changing technologies and security concerns that people interact with daily.
  </p>

  <p>When I started this project, I wanted to look at a lot of different places - emails, websites masking themselves as antivirus popups, and even cultural understandings of what it means to be a hacker. So in my typical fashion, I created a project so large that no mere mortal Master's candidate would be able to complete within a respectable amount of time. While the temptation to remain a student indefinitely has undoubtedly been tempting, I was suggested to examine phishing emails for "ease of use." (Un)surprisingly, there wasn't a large amount of data available for me to analyze. Researchers who have looked into phishing emails, such as Derek Ross' <a href="https://eric.ed.gov/?id=EJ855621" target="_blank" rel="noopener noreferrer"><i>Ars Dictaminus Perverted</i></a>, tended to collect their own from personal accounts. (It is important to note the year of this publication was 2009, suggesting that data was limited still, then.) I had difficulty capturing data from my personal email account as well, as Gmail's spam filter was too powerful. I did at one point sign up for an OX (OpeneXchange) mail account through my domain name provider, but even with submitting my email into various forms and places, I had hardly any luck on the spam front.
  </p>

  <p>After months of trying to find sources on what to use, I found the holy grail - the <a href="https://www.cs.cmu.edu/~enron/" target="_blank" rel="noopener noreferrer">Enron Email Dataset</a>. The Enron dataset is incredibly important, as it is one of the few, possibly only publicly available dataset. Since releasing a cache of emails would be a huge security risk, most companies won't release that data into the wild. The only reason we have this dataset publicly is due to it being uploaded during the Federal Energy Regulatory Commission's investigation against Enron. Because of its unique (and scarce) availability, it's a very common dataset for machine learning, like Parakweet Lab's Email Intent Data Set, which uses this same cache to detect intent within an email message. I finally thought, "wow, that's <i>a lot</i> of data," but since most of it had been from the early to mid-2000s I found it challenging to work with when dealing with modern trends such as clone phishing.</p>

  <p>Many rhetoricians are interested in looking at past events to understand how current trends operate, and that's an excellent path to travel. However, looking at emails from 2004 is the equivalent of a student examining ancient Sumerian to understand the English language. Which is a valid methodology, and it can be exciting and fun, but there's been <i>so much change</i> in those near 4,000 years that those connections aren't exactly helpful. Much like with phishing, going from 2001 to 2019 is the equivalent of millennia, and there has been an exponential evolution in how we operate and communicate online in less than 20 years.
  </p>

  <p>Think back to when you were on the internet in 2001 - Youtube didn't exist, Google was barely on the radar to the public, and <a href="https://www.washingtonpost.com/news/the-intersect/wp/2014/12/15/from-lycos-to-ask-jeeves-to-facebook-tracking-the-20-most-popular-web-sites-every-year-since-1996" target="_blank" rel="noopener noreferrer">AOL was the most visited website of all time</a>. But we're in 2019 now, and you no longer have to use dial-up to access the internet (unless you want to.) The evolution of the internet as an always-on, social space for everyone has impacted how communication (and exploitation) operates. Even with this rapid change, I don't mean to say these artifacts fail to inform how phishing has worked and continues to work today. Instead, the methods now are much more sophisticated than writing a letter, and rhetorical researchers should be aware of these changes to understand what's happening with recent phishing attacks. Phishing attempts have long since changed from the standard personal solicitation scams. That's not to say that these scams don't exist still (because they do), but the methods of obtaining the payload, whether it be credentials, personal information, or even access to your computer itself, has become more sophisticated than a simple letter.
  </p>

  <p>A great example of this is research published on 09.04.2019 from Checkpoint discussing a new phishing scam that targets individuals by falsifying an over-the-air (OTA) data transmission through SMS. It works via a man-in-the-middle attack [define] which tricks the user into believing they are receiving a genuine request to provision their phone. Since provisioning is standard practice for cellular carriers when setting up a customer on their network, it's unsurprising that this attack is so effective. The fantastic thing about this phishing attack is that it uses the same OTA standards that a genuine provisioning request is sent through! When the user accepts,<i>all network traffic</i> is accessible to the attacker, since the phone was reprovisioned to give access. Therefore someone illiterate, or merely unsuspecting, on how OTA updates work is vulnerable to this sort of attack.
  </p>

  <p>This lack of awareness is precisely the problem that security professionals (and myself) are trying to understand and address. While not every attack is as potentially undetectable as this one, I recognize the phishing game has changed considerably. Which brings my main question to this: "How do we have a user tell the difference between a malicious act and a genuine act from a trusted person/provider/entity?" From a security standpoint, it can feel incredibly daunting, especially when you're trying to explain to users the intricacies of phishing tactics and how to protect them, while they don't understand why the <a href="https://www.reddit.com/r/talesfromtechsupport/comments/4yfuj4/i_broke_my_coffee_holder/" target="_blank" rel="noopener noreferrer">built-in cupholder</a> in their computer stopped working. But the rhetorical standpoint feels just as daunting since a lot of the language is visual and remarkably similar to legitimate sources. I recognize that it's going to be a lot like teaching my students in freshman composition class about rhetoric. Difficult, but manageable in small doses, I think.
  </p>

  <p>I consider this project - one that imparts rhetoric as a key factor to training - as a novel idea. Companies such as KnowBe4, SANS, and many others use psychological and an understanding of social engineering to make their products, and for what it's worth, they are useful products. However, if we think about security issues like an infection, security awareness training programs function like a band-aid instead of an antiseptic. They treat <b>the symptoms</b> as opposed to the underlying disease: a lack of caring about critical thinking.
  </p>

  <p>What I mean by that is existing training programs look at how to change people's behavior through psychological <a href="https://event.on24.com/wcc/r/2090640/094544FEFFA8D253A355F792E87DC543" target="_blank" rel="noopener noreferrer">"mind tricks"</a>. So while you can psychosocially analyze people to your heart's content, there's still a gap in understanding how the language causes people to act. Not everything is behavior modification, after all! I noticed that these programs don't look at the agency of the audience, or the exigency demonstrated outside of "your company is at risk, so don't do this." It creates a very dull scenario for an employee. I think back to my own experiences with mandatory training, and often considered ways to complete it in the background so I could get on with "more important" things. I'm sure you've experienced the same feelings as well.
  </p>

  <p>As dull as they seem though, these pieces of training are essential, and part of my work is going to understand how to tailor that exigency to be effective. Because to persuade an audience to react, they need convincing that a problem exists, they're affected by it, it's urgent, and there's a reasonable solution to that problem. Without these critical factors, the training is at risk of being rendered meaningless. Outside of spending tens of thousands of dollars, it wastes valuable time for a company, its employees, and creates a culture that believes "security is a waste of time," <a href="https://event.on24.com/wcc/r/2090640/094544FEFFA8D253A355F792E87DC543" target="_blank" rel="noopener noreferrer">a significant issue now in organizations</a>.
  </p>

  <p>I recognize that saying we need to think critically sounds like every other talk about creating awareness of a problem and educating someone on how to do things "the right way." That all we need to do is think critically, and the problem is solved. I also recognize how cliche it sounds, but thinking critically is <i>precisely</i> what we have to train people to do if corporations (and individuals)
  want to understand, manage, and mitigate security risks.
  </p>

  <p>Being an educator in various fields (robotics, educational technology, and composition/argument, respectively) has given me different terministic screens to look at the problem of critical thinking. Each domain approaches the subject <i>very </i>differently, and it's quite easy to see why there is such a disconnect in the technical versus the humanities. It reminds me of the ideas of Ronald Heifitz, an expert in leadership training who discusses the challenges of <a href="https://hbr.org/2002/06/a-survival-guide-for-leaders" target="_blank" rel="noopener noreferrer">technical and adaptive change</a> within organizational problems.
  </p>

  <p>Technical challenges are easy to see and easy to fix, while adaptive challenges require considerable effort to understand, and are often experimental in how they are solved. The main issue I've seen in corporate environments is that they treat many, if not most, of the problems with security as a technical challenge, as opposed to adaptive. These problems can be solved partially with technical solutions, such as the examples provided in <a href="https://www.techrepublic.com/article/the-challenges-with-preventing-phishing-attacks-an-insiders-perspective/" target="_blank" rel="noopener noreferrer">an interview with Steven Cox</a>, VP and CSA of the security company CyberAuth. While I agree with Mr. Cox on his ideas about how to combat the onslaught of malicious attacks on users, what I <i>don't</i>see is a willingness to adapt psychologically (but more importantly, rhetorically) aside from creating a carrot-on-a-stick with a fancy UX. Don't get me wrong - I appreciate <a href="https://www.secureauth.com/blog/mobile-based-authentication" target="_blank" rel="noopener noreferrer">symbol-to-accept</a>, and it is helpful in some situations, but you can't tailor emails, websites, and everything else <i>outside</i> of an organization to provide the same functions. What I see is a service trains users to think about a specific instance (pushing a corresponding image on a secondary device to confirm authenticity) rather than the internet experience as a whole. It's like a CAPTCHA - do you ever think about them outside of the event itself? Does it even register as a security measure to you anymore, or just "one more thing" to click on to authenticate? What does it even mean to you outside of the moment you're using it - does it even mean anything?
  </p>

  <p>I believe this disconnect is part of the problem with phishing training. It functions as a technical solution to a technical problem which doesn't create value to the audience, who don't identify with it outside of being a situational problem. In reality, this training needs to be adaptive, something extrapolated to other areas of life to create value for the information to be retained. That is where rhetoric comes in. Action. Identification. Meaning-making. All of the <i>good stuff</i> that helps us understand why things are the way they are, how they make us human, and what all that means.</p>

  <p>As a final note, my analysis of phishing emails is only one aspect of Security Awareness Training. There is much, much more involved in these pieces of training than phishing, but I chose to analyze this specific portion of training due to data availability. I am aware that many anti-phishing products masquerade as holistic Security Awareness Training solutions, but that is not my intent here. I see this Master's project as a framework for Providentia Security's training endeavors, and can only hope to expand the knowledge gained here to other areas of awareness training. I hope the research in the following pages is proof of that.</p>
